{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import threading\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, image_model, text_model, optimizer_image, optimizer_text, criterion,\n",
    "          scheduler_image, scheduler_text, device, trade_off_ii=1, trade_off_cc=1):\n",
    "    \"\"\"\n",
    "    Trains the image and text models using the provided dataloader and optimizer.\n",
    "\n",
    "    Parameters:\n",
    "        dataloader (torch.utils.data.DataLoader): The dataloader used for training.\n",
    "        image_model (torch.nn.Module): The image model to be trained.\n",
    "        text_model (torch.nn.Module): The text model to be trained.\n",
    "        optimizer_image (torch.optim.Optimizer): The optimizer used for training the image model.\n",
    "        optimizer_text (torch.optim.Optimizer): The optimizer used for training the text model.\n",
    "        criterion (torch.nn.Module): The loss function used for training.\n",
    "        scheduler_image (torch.optim.lr_scheduler._LRScheduler): The learning rate scheduler for the image optimizer.\n",
    "        scheduler_text (torch.optim.lr_scheduler._LRScheduler): The learning rate scheduler for the text optimizer.\n",
    "        trade_off_ili (float, optional): The trade off between image-image loss and text-text loss. Defaults to 1.\n",
    "        trade_off_cc (float, optional): The trade off between caption-caption loss and image-caption loss. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        float: The average loss over the epoch.\n",
    "    \"\"\"\n",
    "    loss_epoch = 0\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        image_model.train()\n",
    "        text_model.train()\n",
    "\n",
    "        batch_size = batch[0].shape[0]\n",
    "        image1, image2, caption1, caption2 = batch[0], batch[1], batch[3], batch[4]\n",
    "\n",
    "        _, embed_image1 = image_model(image1, device)\n",
    "        _, embed_image2 = image_model(image2, device)\n",
    "        _, embed_caption1 = text_model(caption1, device)\n",
    "        _, embed_caption2 = text_model(caption2, device)\n",
    "\n",
    "        intra_loss = (trade_off_ii * criterion(embed_image1, embed_image2, batch_size) +\n",
    "                      trade_off_cc * criterion(embed_caption1, embed_caption2, batch_size))\n",
    "\n",
    "        intra_loss.backward()\n",
    "\n",
    "        optimizer_image.step()\n",
    "        optimizer_text.step()\n",
    "\n",
    "        optimizer_image.zero_grad()\n",
    "        optimizer_text.zero_grad()\n",
    "\n",
    "        scheduler_image.step()\n",
    "        scheduler_text.step()\n",
    "\n",
    "        loss_epoch += intra_loss.item()\n",
    "\n",
    "        del batch, image1, image2, caption1, caption2, embed_image1, embed_image2, embed_caption1, embed_caption2, intra_loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = loss_epoch / len(dataloader)\n",
    "    return epoch_loss\n",
    "def test(dataloader, image_model, text_model, criterion, device, trade_off_ii=1, trade_off_cc=1):\n",
    "    \"\"\"\n",
    "    Calculate the loss of the model using dataloader, image model, text model,\n",
    "    and criterion on the given device with the given trade_off values.\n",
    "\n",
    "    Args:\n",
    "    dataloader (DataLoader): The dataloader to use for iterating over the data.\n",
    "    image_model (nn.Module): The image model used to extract image features.\n",
    "    text_model (nn.Module): The text model used to extract text features.\n",
    "    criterion (nn.Module): The criterion used to calculate the loss.\n",
    "    device (str): The device to use for computation.\n",
    "    trade_off_ii (float, optional): The trade off value for image features. Default is 1.\n",
    "    trade_off_cc (float, optional): The trade off value for text features. Default is 1.\n",
    "\n",
    "    Returns:\n",
    "    float: The epoch loss.\n",
    "    \"\"\"\n",
    "\n",
    "    loss_epoch = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            image_model.eval()\n",
    "            text_model.eval()\n",
    "            batch_size = batch[0].shape[0]\n",
    "            image1, image2, caption1, caption2 = batch[0], batch[1], batch[3], batch[4]\n",
    "\n",
    "            _, embed_image1 = image_model(image1, device)\n",
    "            _, embed_image2 = image_model(image2, device)\n",
    "            _, embed_caption1 = text_model(caption1, device)\n",
    "            _, embed_caption2 = text_model(caption2, device)\n",
    "\n",
    "            intra_loss = (trade_off_ii * criterion(embed_image1, embed_image2, batch_size) +\n",
    "                          trade_off_cc * criterion(embed_caption1, embed_caption2, batch_size))\n",
    "\n",
    "            loss_epoch += intra_loss.item()\n",
    "\n",
    "            del batch, image1, image2, caption1, caption2, embed_image1, embed_image2, embed_caption1, embed_caption2, intra_loss\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = loss_epoch / len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir toy_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
