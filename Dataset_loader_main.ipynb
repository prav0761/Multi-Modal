{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import threading\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel, OpenAIGPTLMHeadModel\n",
    "from nltk.corpus import wordnet\n",
    "from caption_transforms import SimCLRData_Caption_Transform\n",
    "from image_transforms import SimCLRData_image_Transform\n",
    "from dataset import FlickrDataset\n",
    "from models import ResNetSimCLR,OpenAI_SIMCLR\n",
    "from utils import get_gpu_stats,layerwise_trainable_parameters,count_trainable_parameters\n",
    "from metrics import ContrastiveLoss\n",
    "from metrics import LARS,Optimizer_simclr\n",
    "from logger import Logger\n",
    "from train_fns import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--seed SEED]\n",
      "                             [--modality_type MODALITY_TYPE]\n",
      "                             [--resnet_model RESNET_MODEL]\n",
      "                             [--gpt_model GPT_MODEL]\n",
      "                             [--image_projection_dim IMAGE_PROJECTION_DIM]\n",
      "                             [--text_projection_dim TEXT_PROJECTION_DIM]\n",
      "                             [--resnet_layer RESNET_LAYER]\n",
      "                             [--gpt_layer GPT_LAYER]\n",
      "                             [--temperature TEMPERATURE]\n",
      "                             [--total_epochs TOTAL_EPOCHS]\n",
      "                             [--batch_size BATCH_SIZE]\n",
      "                             [--optimizer_type OPTIMIZER_TYPE]\n",
      "                             [--learning_rate LEARNING_RATE]\n",
      "                             [--momentum MOMENTUM]\n",
      "                             [--weight_decay WEIGHT_DECAY]\n",
      "                             [--num_workers NUM_WORKERS]\n",
      "                             [--trade_off_ii TRADE_OFF_II]\n",
      "                             [--trade_off_cc TRADE_OFF_CC]\n",
      "                             [--graph_save_dir GRAPH_SAVE_DIR]\n",
      "                             [--trial_number TRIAL_NUMBER]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /run/user/879290/jupyter/kernel-45a10228-9a10-40b3-8e10-8fc22fabb14f.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/apps/intel17/python3/3.6.3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def get_args() -> argparse.Namespace:\n",
    "    \"\"\"\n",
    "    Parse command line arguments.\n",
    "\n",
    "    Returns:\n",
    "        argparse.Namespace: the parsed command line arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(description='SimCLR with Image and Caption Data')\n",
    "    parser.add_argument('--seed',\n",
    "                        type=int,\n",
    "                        default=53,\n",
    "                        help='random_seed')\n",
    "    parser.add_argument('--modality_type',\n",
    "                        type=str,\n",
    "                        default='image_caption',\n",
    "                        help='type of modality (image_caption or image)')\n",
    "    parser.add_argument('--resnet_model',\n",
    "                        type=str,\n",
    "                        default='resnet50',\n",
    "                        help='type of ResNet model to use (resnet18, resnet34, resnet50, resnet101, resnet152)')\n",
    "    parser.add_argument('--gpt_model',\n",
    "                        type=str,\n",
    "                        default='openai-gpt',\n",
    "                        help='type of GPT model to use (gpt, gpt2, gpt2-medium, gpt2-large)')\n",
    "    parser.add_argument('--image_projection_dim',\n",
    "                        type=int,\n",
    "                        default=128,\n",
    "                        help='dimension of the projected image embedding')\n",
    "    parser.add_argument('--text_projection_dim',\n",
    "                        type=int,\n",
    "                        default=128,\n",
    "                        help='dimension of the projected text embedding')\n",
    "    parser.add_argument('--resnet_layer',\n",
    "                        type=str,\n",
    "                        default='layer4',\n",
    "                        help='which ResNet layer to use as the encoder')\n",
    "    parser.add_argument('--gpt_layer',\n",
    "                        type=str,\n",
    "                        default='h.11',\n",
    "                        help='which GPT layer to use as the encoder')\n",
    "    parser.add_argument('--temperature',\n",
    "                        type=float,\n",
    "                        default=0.07,\n",
    "                        help='temperature parameter for contrastive loss')\n",
    "    parser.add_argument('--total_epochs',\n",
    "                        type=int,\n",
    "                        default=100,\n",
    "                        help='number of total epochs to train the model')\n",
    "    parser.add_argument('--batch_size',\n",
    "                        type=int,\n",
    "                        default=64,\n",
    "                        help='batch size for training')\n",
    "    parser.add_argument('--optimizer_type',\n",
    "                        type=str,\n",
    "                        default='sgd',\n",
    "                        help='type of optimizer to use (adam, sgd, lars)')\n",
    "    parser.add_argument('--learning_rate',\n",
    "                        type=float,\n",
    "                        default=0.03,\n",
    "                        help='learning rate for optimizer')\n",
    "    parser.add_argument('--momentum',\n",
    "                        type=float,\n",
    "                        default=0.09,\n",
    "                        help='momentum for optimizer')\n",
    "    parser.add_argument('--weight_decay',\n",
    "                        type=float,\n",
    "                        default=1e-4,\n",
    "                        help='weight decay for optimizer')\n",
    "    parser.add_argument('--num_workers',\n",
    "                        type=int,\n",
    "                        default=4,\n",
    "                        help='number of workers for dataloader')\n",
    "    parser.add_argument('--trade_off_ii',\n",
    "                        type=float,\n",
    "                        default=1,\n",
    "                        help='trade-off weight for image-image similarity loss')\n",
    "    parser.add_argument('--trade_off_cc',\n",
    "                        type=float,\n",
    "                        default=1,\n",
    "                        help='trade-off weight for caption-caption similarity loss')\n",
    "    parser.add_argument('--graph_save_dir',\n",
    "                        type=str,\n",
    "                        default='/home1/08629/pradhakr/cv_project/graphs/image_caption',\n",
    "                        help='directory to save the loss graphs')\n",
    "    parser.add_argument('--trial_number',\n",
    "                        type=int,\n",
    "                        help='trial number')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "\n",
    "    # Create train and test datasets with image and caption transforms\n",
    "    train_dataset = FlickrDataset('data/', \"data/train\", 'train',\n",
    "                                  image_transform=SimCLRData_image_Transform(),\n",
    "                                  caption_transform=SimCLRData_Caption_Transform())\n",
    "\n",
    "    test_dataset = FlickrDataset('data/', \"data/test\", 'test',\n",
    "                                 image_transform=SimCLRData_image_Transform(),\n",
    "                                 caption_transform=SimCLRData_Caption_Transform())\n",
    "\n",
    "    # Set the batch size and create train and test data loaders\n",
    "    batch_size = args.batch_size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=args.num_workers,\n",
    "                                  pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=args.num_workers,\n",
    "                                 pin_memory=True)\n",
    "\n",
    "    # Set device to CUDA if available, otherwise to CPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initialize ResNetSimCLR model\n",
    "    model_resnet = ResNetSimCLR(\n",
    "            model=args.resnet_model,\n",
    "            projection_dim=args.image_projection_dim,\n",
    "            layers_to_train=[args.resnet_layer]\n",
    "        ).to(device)\n",
    "\n",
    "        # Initialize OpenAI_SIMCLR model\n",
    "    gpt_model = OpenAI_SIMCLR(\n",
    "            model=args.gpt_model,\n",
    "            projection_dim=args.text_projection_dim,\n",
    "            layers_to_train=[args.gpt_layer]\n",
    "        ).to(device)\n",
    "\n",
    "        # Define loss function\n",
    "    NXTENT_loss = ContrastiveLoss(device, temperature=args.temperature)\n",
    "\n",
    "        # Define optimizers and schedulers\n",
    "    optimizer_image = Optimizer_simclr(optimizer_name=args.optimizer_type,\n",
    "                                           model_parameters=model_resnet.parameters(),\n",
    "                                           lr=args.learning_rate,\n",
    "                                           momentum=args.momentum,\n",
    "                                           weight_decay=args.weight_decay)\n",
    "\n",
    "    scheduler_image = optimizer_image.scheduler\n",
    "    optimizer_image = optimizer_image.optimizer\n",
    "\n",
    "    optimizer_text = Optimizer_simclr(optimizer_name=args.optimizer_type,\n",
    "                                          model_parameters=gpt_model.parameters(),\n",
    "                                          lr=args.learning_rate,\n",
    "                                          momentum=args.momentum,\n",
    "                                          weight_decay=args.weight_decay)\n",
    "\n",
    "    scheduler_text = optimizer_text.scheduler\n",
    "    optimizer_text = optimizer_text.optimizer\n",
    "\n",
    "    # Initialize trial number\n",
    "\n",
    "    # Define paths for logs and files\n",
    "    log_dir = os.path.join(os.getenv('WORK'), 'cv_project')\n",
    "    image_caption_filename = os.path.join(log_dir, args.modality_type)\n",
    "    train_log = os.path.join(image_caption_filename, f'train_{args.trial_number}.log')\n",
    "    image_model_log = os.path.join(image_caption_filename, f'image_model_{args.trial_number}.pth')\n",
    "    text_model_log = os.path.join(image_caption_filename, f'text_model_{args.trial_number}.pth')\n",
    "    graph_save_dir = os.path.join(args.graph_save_dir, args.modality_type)\n",
    "\n",
    "    # Create a logger object and start training\n",
    "    logger_save = Logger(train_log, image_model_log, text_model_log, args.optimizer_type,\n",
    "                         args.learning_rate, args.weight_decay, batch_size, args.momentum, args.temperature,\n",
    "                         args.total_epochs)\n",
    "    logger_save.start_training()\n",
    "    # Loop through epochs and train the models\n",
    "    for epoch in tqdm(range(args.total_epochs)):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Train the models and get the loss\n",
    "        train_loss = train(dataloader=train_loader, image_model=model_resnet, text_model=gpt_model,\n",
    "                           optimizer_image=optimizer_image, optimizer_text=optimizer_text, criterion=NXTENT_loss,\n",
    "                           scheduler_image=scheduler_image, scheduler_text=scheduler_text, device=device,\n",
    "                           trade_off_ii=args.trade_off_ii, trade_off_cc=args.trade_off_cc)\n",
    "\n",
    "        # Test the models and get the loss\n",
    "        test_loss = test(dataloader=test_loader, image_model=model_resnet, text_model=gpt_model, criterion=NXTENT_loss, device=device\n",
    "                         ,trade_off_ii=args.trade_off_ii, trade_off_cc=args.trade_off_cc)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Log the results of the epoch\n",
    "        logger_save.log(epoch + 1, model_resnet, gpt_model, train_loss, test_loss, end - start)\n",
    "\n",
    "    # End training and plot the losses\n",
    "    logger_save.end_training()\n",
    "    logger_save.plot_losses(args.trial_number, graph_save_dir)\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    # Parse command-line arguments\n",
    "    args = get_args()\n",
    "\n",
    "    # Call the main function with the parsed arguments\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
