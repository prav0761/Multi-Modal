{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "import time\n",
    "import io\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import threading\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import OpenAIGPTTokenizer, OpenAIGPTModel, OpenAIGPTLMHeadModel\n",
    "from nltk.corpus import wordnet\n",
    "from caption_transforms import SimCLRData_Caption_Transform\n",
    "from image_transforms import SimCLRData_image_Transform\n",
    "from dataset import FlickrDataset\n",
    "from models import ResNetSimCLR,OpenAI_SIMCLR\n",
    "from utils import get_gpu_stats,layerwise_trainable_parameters,count_trainable_parameters\n",
    "from metrics import ContrastiveLoss\n",
    "from metrics import LARS,Optimizer_simclr\n",
    "from logger import Logger\n",
    "from train_fns import train, test\n",
    "\"\"\"import nltk\n",
    "nltk.download('omw-1.4')\"\"\"\n",
    "get_gpu_stats()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from datetime import datetime\n",
    "#/home1/08629/pradhakr/cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# Set the seed for PyTorch's random number generator\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Create train and test datasets using FlickrDataset\n",
    "train_dataset = FlickrDataset('data/', \"data/train\", 'train',\n",
    "                              image_transform=SimCLRData_image_Transform(),\n",
    "                              caption_transform=SimCLRData_Caption_Transform())\n",
    "\n",
    "test_dataset = FlickrDataset('data/', \"data/test\", 'test',\n",
    "                             image_transform=SimCLRData_image_Transform(),\n",
    "                             caption_transform=SimCLRData_Caption_Transform())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create train and test data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1, img2, caption,caption1, caption2 = test_dataset[5]\n",
    "plt.imshow(img1.permute(1, 2, 0))\n",
    "\n",
    "# Show augmented image\n",
    "plt.figure()\n",
    "plt.imshow(img2.permute(1, 2, 0))\n",
    "print('orginal caption:',caption)\n",
    "print('caption1:',caption1)\n",
    "print('caption2:',caption2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    s=i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet=ResNetSimCLR(model='resnet18',projection_dim=128,layers_to_train=['layer4']).to(device)\n",
    "print('total parameters_resnet',count_trainable_parameters(model_resnet))\n",
    "gpt_model = OpenAI_SIMCLR(model='openai-gpt', projection_dim=128,layers_to_train=['h.11']).to(device)\n",
    "print('total parameters_gpt',count_trainable_parameters(gpt_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_image,b_image=model_resnet(s[0],device)\n",
    "a_image1,b_image1=model_resnet(s[1],device)\n",
    "a_caption,b_caption=gpt_model(s[3],device)\n",
    "a_caption1,b_caption1=gpt_model(s[4],device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_image.shape,b_caption.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NXTENT_loss=ContrastiveLoss(device,temperature=0.07)\n",
    "print(NXTENT_loss(b_image,b_image1, batch_size)+NXTENT_loss(b_caption,b_caption1,batch_size).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learning_rate=0.03\n",
    "Momentum=0.09\n",
    "temperature=0.07\n",
    "weight_decay=1e-4\n",
    "optimizer_type='sgd'\n",
    "NXTENT_loss=ContrastiveLoss(device,temperature=temperature)\n",
    "optimizer_image = Optimizer_simclr(optimizer_name=optimizer_type, model_parameters=model_resnet.parameters(), lr=Learning_rate,\n",
    "                             momentum=Momentum, weight_decay=weight_decay)\n",
    "optimizer_text = Optimizer_simclr(optimizer_name=optimizer_type, model_parameters=gpt_model.parameters(), lr=Learning_rate,\n",
    "                             momentum=Momentum, weight_decay=weight_decay)\n",
    "OPTIMIZER_image=optimizer_image.optimizer\n",
    "scheduler_image=optimizer_image.scheduler\n",
    "OPTIMIZER_text=optimizer_text.optimizer\n",
    "scheduler_text=optimizer_text.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader,  image_model,  text_model,  optimizer_image,   optimizer_text,\n",
    "          criterion,  scheduler_image, scheduler_text,   trade_off_ii=1,   trade_off_cc=1):   \n",
    "        \n",
    "    loss_epoch=0\n",
    "    for idx,batch in enumerate(dataloader):\n",
    "        image_model.train()\n",
    "        text_model.train()\n",
    "        batch_size=batch[0].shape[0]\n",
    "        image1,image2,caption1,caption2 =batch[0],batch[1],batch[3],batch[4]\n",
    "\n",
    "        _,embed_image1=image_model(image1,device)\n",
    "\n",
    "        _,embed_image2=image_model(image2,device)\n",
    "\n",
    "        _,embed_caption1=text_model(caption1,device)\n",
    "\n",
    "        _,embed_caption2=text_model(caption2,device)\n",
    "        intra_loss=(trade_off_ii*criterion(embed_image1,embed_image2,batch_size) +\n",
    "                        trade_off_cc*criterion(embed_caption1,embed_caption2,batch_size))\n",
    "\n",
    "        intra_loss.backward()\n",
    "\n",
    "        optimizer_image.step()\n",
    "        optimizer_text.step()\n",
    "\n",
    "        optimizer_image.zero_grad()\n",
    "        optimizer_text.zero_grad()\n",
    "        \n",
    "        scheduler_image.step()\n",
    "        scheduler_text.step()\n",
    "        \n",
    "        loss_epoch += intra_loss.item()\n",
    "        \n",
    "        del batch, image1, image2, caption1, caption2, embed_image1, embed_image2, embed_caption1, embed_caption2, intra_loss\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "    epoch_loss=loss_epoch/len(dataloader)\n",
    "    return epoch_loss\n",
    "\n",
    "def test(dataloader,image_model,text_model,criterion,trade_off_ii=1,trade_off_cc=1):\n",
    "    \n",
    "        \n",
    "        \n",
    "    trade_off_ii,trade_off_cc=1,1\n",
    "    loss_epoch=0\n",
    "    with torch.no_grad():\n",
    "        for idx,batch in enumerate(dataloader):\n",
    "            image_model.eval()\n",
    "            text_model.eval()\n",
    "            batch_size=batch[0].shape[0]\n",
    "            image1,image2,caption1,caption2 =batch[0],batch[1],batch[3],batch[4]\n",
    "\n",
    "            _,embed_image1=image_model(image1,device)\n",
    "\n",
    "            _,embed_image2=image_model(image2,device)\n",
    "\n",
    "            _,embed_caption1=text_model(caption1,device)\n",
    "\n",
    "            _,embed_caption2=text_model(caption2,device)\n",
    "\n",
    "            intra_loss=(trade_off_ii*criterion(embed_image1,embed_image2,batch_size) +\n",
    "                            trade_off_cc*criterion(embed_caption1,embed_caption2,batch_size))\n",
    "\n",
    "\n",
    "            loss_epoch += intra_loss.item()\n",
    "\n",
    "            del batch, image1, image2, caption1, caption2, embed_image1, embed_image2, embed_caption1, embed_caption2, intra_loss\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss=loss_epoch/len(dataloader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs=100\n",
    "trial_number=1\n",
    "log_dir = os.path.join(os.getenv('WORK'), 'cv_project')\n",
    "image_caption_filename=os.path.join(log_dir, 'image_caption')\n",
    "train_log=os.path.join(image_caption_filename, f'train_{trial_number}.log')\n",
    "image_model_log=os.path.join(image_caption_filename, f'image_model_{trial_number}.pth')\n",
    "text_model_log=os.path.join(image_caption_filename, f'text_model_{trial_number}.pth')\n",
    "graph_save_dir='/home1/08629/pradhakr/cv/graphs/image_caption'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_save=Logger(train_log,image_model_log,text_model_log, optimizer_type, \n",
    "            Learning_rate, weight_decay, batch_size,Momentum,temperature,total_epochs)\n",
    "logger_save.start_training()\n",
    "\n",
    "for epoch in tqdm(range(total_epochs)):\n",
    "    \n",
    "    start=time.time()\n",
    "    \n",
    "    \n",
    "    train_loss=train(dataloader=train_loader,  image_model=model_resnet,  text_model=gpt_model,\n",
    "    optimizer_image=OPTIMIZER_image,   optimizer_text =  OPTIMIZER_text,criterion=NXTENT_loss,\n",
    "                     scheduler_image=scheduler_image, scheduler_text=scheduler_text,   trade_off_ii=1,   trade_off_cc=1)\n",
    "    test_loss=test(dataloader=test_loader,  image_model=model_resnet,  text_model=gpt_model,criterion =NXTENT_loss\n",
    "         ,trade_off_ili=1,trade_off_cc=1)\n",
    "    \n",
    "    end=time.time()\n",
    "    logger_save.log(epoch+1,model_resnet,gpt_model,  train_loss, test_loss, end-start)\n",
    "\n",
    "logger_save.end_training()\n",
    "logger_save.plot_losses(trial_number,graph_save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
