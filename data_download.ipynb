{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flickrapi\n",
    "api_key = '60624b0963634d316ccb8a12abdfc644'\n",
    "api_secret = '3678327259a167f1'\n",
    "flickr = flickrapi.FlickrAPI(api_key, api_secret, format='parsed-json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of travel photos: 92471\n"
     ]
    }
   ],
   "source": [
    "photos = flickr.photos.search(tags='Travel',extras='tags', per_page=20)\n",
    "total_photos = photos[\"photos\"][\"total\"]\n",
    "\n",
    "print(f\"Number of travel photos: {total_photos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "#from transformers import VisionEncoderDecoderModel, ViTImageProcessor, AutoTokenizer\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Define the transformation to apply to the image\\ntransform = transforms.Compose([\\n    transforms.Resize(256),\\n    transforms.CenterCrop(224),\\n    transforms.ToTensor()]\\n    )\\nfor photo in photos['photos']['photo']:\\n    photo_url = 'https://farm{}.staticflickr.com/{}/{}_{}.jpg'.format(photo['farm'], photo['server'], photo['id'], photo['secret'])\\n    if photo_url:\\n        response = requests.get(photo_url)\\n        img = Image.open(BytesIO(response.content))\\n\\n        # Apply the transformation to the image\\n        img = transform(img)\\n\\n        # Display the image\\n        plt.imshow(img.permute(1, 2, 0))\\n        plt.show()\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Define the transformation to apply to the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor()]\n",
    "    )\n",
    "for photo in photos['photos']['photo']:\n",
    "    photo_url = 'https://farm{}.staticflickr.com/{}/{}_{}.jpg'.format(photo['farm'], photo['server'], photo['id'], photo['secret'])\n",
    "    if photo_url:\n",
    "        response = requests.get(photo_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        # Apply the transformation to the image\n",
    "        img = transform(img)\n",
    "\n",
    "        # Display the image\n",
    "        plt.imshow(img.permute(1, 2, 0))\n",
    "        plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 1\n",
    "test_ratio = 0\n",
    "search_tag='Vacation'\n",
    "# Specify the number of photos to download\n",
    "num_photos = 25000\n",
    "\n",
    "# Initialize a list to store the downloaded photos\n",
    "downloaded_photos = []\n",
    "\n",
    "# Make multiple API requests to download the photos\n",
    "for page in range(1, (num_photos // 500) + 2):\n",
    "    # Construct the API request URL with the page parameter\n",
    "    url = \"https://www.flickr.com/services/rest/?method=flickr.photos.search&api_key={}&tags={}&per_page=500&page={}&format=json&nojsoncallback=1\".format(api_key, search_tag, page)\n",
    "\n",
    "    # Make the API request and parse the response\n",
    "    response = requests.get(url,timeout=10)\n",
    "    response_dict = json.loads(response.content.decode())\n",
    "\n",
    "    # Extract the photo objects from the response and add them to the downloaded_photos list\n",
    "    downloaded_photos.extend(response_dict['photos']['photo'])\n",
    "\n",
    "    # Break the loop if the requested number of photos have been downloaded\n",
    "    if len(downloaded_photos) >= num_photos:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir='data/'\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "#os.makedirs(train_dir, exist_ok=True)\n",
    "#os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Create caption files for train and test sets\n",
    "train_captions_file = os.path.join(output_dir, \"train_captions.txt\")\n",
    "test_captions_file = os.path.join(output_dir, \"test_captions.txt\")\n",
    "\"\"\"with open(train_captions_file, \"w\") as f:\n",
    "    pass\n",
    "with open(test_captions_file, \"w\") as f:\n",
    "    pass\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for photo in tqdm(downloaded_photos[10000:11000]):\n",
    "    photo_url = 'https://farm{}.staticflickr.com/{}/{}_{}.jpg'.format(photo['farm'], photo['server'], photo['id'], photo['secret'])\n",
    "    # Create the filename\n",
    "    filename = \"{}_{}.jpg\".format(photo['id'], photo['secret'])\n",
    "    img_path = os.path.join(output_dir, filename)\n",
    "    \n",
    "    train_img_path = os.path.join(train_dir, filename)\n",
    "    test_img_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    if os.path.exists(train_img_path) or os.path.exists(test_img_path):\n",
    "        print(\"Skipping {}, already downloaded\".format(filename))\n",
    "        continue\n",
    "    \n",
    "    # Download the image\n",
    "    response = requests.get(photo_url)\n",
    "    img1 = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    # Apply the transformation to the image\n",
    "    img = transform(img1)\n",
    "    # Generate the image caption\n",
    "    generated_text = image_to_text(photo_url)[0]['generated_text']\n",
    "    \n",
    "    # Choose a random number between 0 and 1 to determine which set the image belongs to\n",
    "    r = random.random()\n",
    "    if r < train_ratio:\n",
    "        # Save the image to the train directory\n",
    "        img_path = os.path.join(train_dir, filename)\n",
    "        with open(train_captions_file, \"a\") as f:\n",
    "            f.write(\"{}\\t{}\\n\".format(filename, generated_text))\n",
    "    else:\n",
    "        # Save the image to the test directory\n",
    "        img_path = os.path.join(test_dir, filename)\n",
    "        with open(test_captions_file, \"a\") as f:\n",
    "            f.write(\"{}\\t{}\\n\".format(filename, generated_text))\n",
    "    \n",
    "    try:\n",
    "        torchvision.utils.save_image(img, img_path)\n",
    "    except FileNotFoundError as e:\n",
    "        print(\"Error: File not found: {}\".format(e))\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "output_filename = \"data.zip\"\n",
    "\n",
    "with zipfile.ZipFile(output_filename, \"w\") as zip_file:\n",
    "    # Add the train directory and all its contents to the zip file\n",
    "    for root, dirs, files in os.walk(train_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zip_file.write(file_path, os.path.relpath(file_path, train_dir))\n",
    "\n",
    "    # Add the test directory and all its contents to the zip file\n",
    "    for root, dirs, files in os.walk(test_dir):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            zip_file.write(file_path, os.path.relpath(file_path, test_dir))\n",
    "\n",
    "    # Add the train and test captions files to the zip file\n",
    "    zip_file.write(train_captions_file, os.path.basename(train_captions_file))\n",
    "    zip_file.write(test_captions_file, os.path.basename(test_captions_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
